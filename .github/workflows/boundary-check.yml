name: Boundary Enforcement Check

on:
  pull_request:
    paths:
      - 'agents/**'
  push:
    branches:
      - main
    paths:
      - 'agents/**'

jobs:
  boundary-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Check planner has no write tools
        run: |
          # Ensure planner never gets write tools
          if grep -A5 'name: planner' agents/*.md | grep -E 'Writer|Editor|Container'; then
            echo "ERROR: Planner has write-level tools!"
            exit 1
          fi
          
      - name: Check integration-agent boundaries
        run: |
          # Ensure integration-agent stays in coordinator role
          if grep -A5 'name: integration-agent' agents/*.md | grep -E 'Bulk File|Container Runner'; then
            echo "ERROR: Integration-agent has execution tools!"
            exit 1
          fi
          
      - name: Verify credit caps
        run: |
          # Planner should have minimal credits
          if grep -A3 'name: planner' agents/*.md | grep 'soft_cap' | grep -v -E 'soft_cap: [1-5][0-9]$'; then
            echo "ERROR: Planner credit cap exceeds 59!"
            exit 1
          fi
          
      - name: Success
        run: echo "✅ All boundary checks passed!"
  
  sandbox-test:
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'new-tool') || contains(github.head_ref, 'tool')
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install Docker
        run: |
          sudo apt-get update
          sudo apt-get install -y docker.io
          sudo systemctl start docker
          sudo chmod 666 /var/run/docker.sock
      
      - name: Pull Python Docker image
        run: docker pull python:3.12-slim
      
      - name: Detect new tools
        id: detect
        run: |
          # Find Python files in tools/ that were added/modified
          NEW_TOOLS=$(git diff --name-only origin/main...HEAD | grep '^tools/.*\.py$' | grep -v __pycache__ | grep -v tool_builder | xargs -I {} basename {} .py || echo "")
          echo "new_tools=$NEW_TOOLS" >> $GITHUB_OUTPUT
          echo "Found tools: $NEW_TOOLS"
      
      - name: Test new tools in sandbox
        if: steps.detect.outputs.new_tools != ''
        run: |
          for tool in ${{ steps.detect.outputs.new_tools }}; do
            echo "Testing tool: $tool"
            python tools/tool_builder/sandbox.py "$tool" || exit 1
          done
      
      - name: Success
        run: echo "✅ All sandbox tests passed!"
  
  sentinel-test:
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'sentinel') || contains(github.head_ref, 'sentinel')
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          pip install pytest pyyaml
      
      - name: Run sentinel tests
        run: |
          python -m pytest tests/test_credit_sentinel.py -v
      
      - name: Test sentinel CLI
        run: |
          # Test CLI commands
          python tools/credit_sentinel_v2.py start test-agent
          python tools/credit_sentinel_v2.py track test-agent test-tool 10 1000
          python tools/credit_sentinel_v2.py metrics
      
      - name: Verify metrics export
        run: |
          python -c "
          from tools.credit_sentinel_v2 import get_sentinel, get_metrics_json
          import json
          
          sentinel = get_sentinel()
          sentinel.track_tool_call('ci-test', 'test-tool', 5, 500)
          
          metrics = json.loads(get_metrics_json())
          assert 'global' in metrics
          assert metrics['global']['total_credits'] >= 5
          print('✅ Metrics export verified')
          "
      
      - name: Success
        run: echo "✅ All sentinel tests passed!"
  
  integration-test:
    runs-on: ubuntu-latest
    if: contains(github.head_ref, 'integration-agent')
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          pip install pytest
      
      - name: Run GitHub client tests
        run: |
          python -m pytest tests/test_github_client.py -v
      
      - name: Check integration-agent manifest
        run: |
          # Verify manifest structure
          if ! grep -q "name: integration-agent" agents/integration-agent.md; then
            echo "ERROR: Integration-agent manifest missing or malformed!"
            exit 1
          fi
          
          # Check tools list
          if ! grep -q "tools: Writer, Think, GitHubClient" agents/integration-agent.md; then
            echo "ERROR: Integration-agent missing required tools!"
            exit 1
          fi
          
          # Verify soft cap
          if ! grep -q "soft_cap: 120" agents/integration-agent.md; then
            echo "ERROR: Integration-agent soft cap not set correctly!"
            exit 1
          fi
      
      - name: Verify no container access
        run: |
          # Integration-agent should not have Container Runner
          if grep -A10 'name: integration-agent' agents/*.md | grep -E 'Container Runner|Docker|Sandbox'; then
            echo "ERROR: Integration-agent has container execution tools!"
            exit 1
          fi
      
      - name: Success
        run: echo "✅ All integration tests passed!"
  
  session-summary-test:
    runs-on: ubuntu-latest
    if: contains(github.head_ref, 'session-summarizer')
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          pip install pytest pyyaml
      
      - name: Run session summarizer tests
        run: |
          python -m pytest tests/test_session_summarizer.py -v
      
      - name: Test summarizer CLI
        run: |
          # Generate a test summary
          python tools/session_summarizer.py
          
          # Validate it
          python tools/session_summarizer.py validate
      
      - name: Test context validator CLI
        run: |
          # Check context status
          python tools/context_validator.py check || true
          
          # Get safe context
          python tools/context_validator.py safe
      
      - name: Validate schema compliance
        run: |
          # Check that schema file is valid JSON
          python -c "
          import json
          with open('schemas/session_summary.schema.json', 'r') as f:
              schema = json.load(f)
          print('✅ Schema is valid JSON')
          
          # Check required fields
          assert 'properties' in schema
          assert 'version' in schema['properties']
          assert 'context_hash' in schema['properties']
          print('✅ Schema has required fields')
          "
      
      - name: Success
        run: echo "✅ All session summary tests passed!"